library(dplyr)
library(tidyr)
library(tidytext)
data("stop_words")
setwd("~/coursera/Coursera-SwiftKey/final/en_US")
# Reading the blog data
b<-file("./en_US.blogs.txt",open = "r")
blog <- readLines(b)
close(b)
# Reading news data
b<-file("./en_US.news.txt",open = "r")
news<- readLines(b)
close(b)
#Reading twitter data
b<-file("./en_US.twitter.txt",open = "r")
tweet<- readLines(b)
close(b)
tweet_tbl<-tibble(source = rep("tweet",length(tweet)),text = tweet)
news_tbl<-tibble(source = rep("news",length(news)),text = news)
blog_tbl<-tibble(source = rep("blog",length(blog)),text = blog)
comb<-bind_rows(blog_tbl,tweet_tbl,news_tbl)
remove(blog_tbl,tweet_tbl,news_tbl)
remove(b,tweet,blog,news)
combineduni<- comb %>% unnest_tokens(word,text) %>% anti_join(stop_words,by ="word")
combineduni <- combineduni %>% count(word,sort=T)
num <- tibble(word =c("1","2","3","4","5","6","7","8","9","10","rt"))
combineduni <- combineduni %>% anti_join(num,by ="word")
combinedbi<- comb %>% unnest_tokens(bigram,text,token = "ngrams",n=2)
combinedbi<-combinedbi %>% separate(bigram,c("word1","word2"),sep = " ")
combinedbi<-combinedbi %>% filter(!word1 %in% stop_words$word,!word2 %in% stop_words$word)
combinedbi<-combinedbi %>% filter(!word1 %in% num$word,!word2 %in% num$word)
combinedbi<-combinedbi %>% unite(bigram,word1,word2,sep = " ")
combinedbi<-combinedbi %>% count(bigram,sort = T)
combinedtri <- comb %>% unnest_tokens(trigram,text,token="ngrams",n=3)
combinedtri <- combinedtri %>% separate(trigram,c("word1,word2,word3"),sep=" ")
combinedtri <- combinedtri %>% filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word & !word3 %in% stop_words$word)
combinedtri <- combinedtri %>% filter(!word1 %in% num$word & !word2 %in% num$word & !word3 %in% num$word)
combinedtri <- combinedtri %>% unite(trigram,word1,word2,word3,sep = " ")
combinedtri<- combinedtri %>% count(trigram,sort = T)